# Content Drafts: Sonnet 4.5 Model Faces Challenges with Long Contexts

**Source:** Anthropic | **Relevance:** 75
**Hot Take:** Are current AI models hitting a wall with context length limitations?

---

## ğŸ¦ Twitter / X

ğŸš¨ BREAKING: Sonnet 4.5 faces existential crisis when asked to remember anything more than a grocery list. Remember when Google's models did something eerily similar? Coincidence? I think not. ğŸ˜

If you're planning on having a deep convo with your AI, better bring a scaffold and some patience. Or, you know, maybe humans aren't that bad after all. ğŸ¤”ğŸ”¥

---

## ğŸ’¼ LinkedIn

ğŸš¨ AI's Kryptonite: Context Length ğŸš¨

In the race to build ever-smarter AI, have we hit a wall with context length limitations? Users of the Sonnet 4.5 model are reporting that it often gets lost in conversation, much like challenges faced by Google's models. This isn't just a bugâ€”it's a feature... of human expectation vs. technical reality.

While sophisticated algorithms can process vast amounts of data, many still struggle to maintain coherence over extended conversations. However, there's a silver lining: techniques like extended thinking and scaffolding show promise in bridging these gaps, serving as mental crutches for our silicon counterparts.

Here's the contrarian take: Instead of focusing solely on increasing context length, should we be rethinking how these models process and prioritize information? Perhaps the future of AI isn't about remembering everything, but about remembering the right things.

Are we trying to solve the wrong problem by pushing for infinite memory? Let's flip the script and consider a new paradigmâ€”one where less could actually be more. What if AI's strength lies not in how much it can remember, but in how effectively it can forget? ğŸ¤”

---

